{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.getcwd() + '/RoBO-master')\n",
    "\n",
    "from robo.fmin import bayesian_optimization\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from operator import add\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "rf = pickle.load(open(\"./rf_surrogate_cnn.pkl\", \"rb\"))\n",
    "cost_rf = pickle.load(open(\"./rf_cost_surrogate_cnn.pkl\", \"rb\"))\n",
    "\n",
    "\n",
    "def objective_function(x, epoch=40):\n",
    "    \"\"\"\n",
    "        Function wrapper to approximate the validation error of the hyperparameter configurations x by the prediction of a surrogate regression model,\n",
    "        which was trained on the validation error of randomly sampled hyperparameter configurations.\n",
    "        The original surrogate predicts the validation error after a given epoch. Since all hyperparameter configurations were trained for a total amount of \n",
    "        40 epochs, we will query the performance after epoch 40.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize all hyperparameters to be in [0, 1]\n",
    "    x_norm = deepcopy(x)\n",
    "    x_norm[0] = (x[0] - (-6)) / (0 - (-6))\n",
    "    x_norm[1] = (x[1] - 32) / (512 - 32)\n",
    "    x_norm[2] = (x[2] - 4) / (10 - 4)\n",
    "    x_norm[3] = (x[3] - 4) / (10 - 4)\n",
    "    x_norm[4] = (x[4] - 4) / (10 - 4)\n",
    "    \n",
    "\n",
    "    x_norm = np.append(x_norm, epoch)\n",
    "    y = rf.predict(x_norm[None, :])[0]\n",
    "\n",
    "    return y\n",
    "\n",
    "def runtime(x, epoch=40):\n",
    "    \"\"\"\n",
    "        Function wrapper to approximate the runtime of the hyperparameter configurations x.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize all hyperparameter to be in [0, 1]\n",
    "    x_norm = deepcopy(x)\n",
    "    x_norm[0] = (x[0] - (-6)) / (0 - (-6))\n",
    "    x_norm[1] = (x[1] - 32) / (512 - 32)\n",
    "    x_norm[2] = (x[2] - 4) / (10 - 4)\n",
    "    x_norm[3] = (x[3] - 4) / (10 - 4)\n",
    "    x_norm[4] = (x[4] - 4) / (10 - 4)\n",
    "    \n",
    "\n",
    "    x_norm = np.append(x_norm, epoch)\n",
    "    y = cost_rf.predict(x_norm[None, :])[0]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRandomHyperparameters():\n",
    "    \"\"\" Function to give some random hyperparameters in the correct interval as a 5 tuple.\n",
    "    \"\"\"\n",
    "    learning_rate = random.uniform(-6, 0)\n",
    "    batch_size = random.randint(32, 512)\n",
    "    filters_1 = random.randint(4, 10)\n",
    "    filters_2 = random.randint(4, 10)\n",
    "    filters_3 = random.randint(4, 10)\n",
    "    return [learning_rate, batch_size, filters_1, filters_2, filters_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomSearch(iterations):\n",
    "    \"\"\" Performs random search and returns the performance after each iteration as a list. \"\"\"\n",
    "    incumbent = float(\"inf\")\n",
    "    performances = list()\n",
    "    for iteration in range(iterations):\n",
    "        hyperparameters = getRandomHyperparameters()\n",
    "        objective_function_value = objective_function(hyperparameters)\n",
    "        if objective_function_value < incumbent:\n",
    "            incumbent = objective_function_value\n",
    "        performances.append(incumbent)\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testRandomSearch(iterations, tests):\n",
    "    \"\"\" Give average incumbent development for test many learning curves.\n",
    "    \"\"\"\n",
    "    result = randomSearch(iterations)\n",
    "    for test in range(tests-1):\n",
    "        result = map(add, result, randomSearch(iterations))\n",
    "    return [el / tests for el in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testRandomSearch(50, 10))\n",
    "plt.savefig('incumbentRandom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# Defining the bounds and dimensions of the input space\n",
    "lower = np.array([-6, 32, 4, 4, 4])\n",
    "upper = np.array([0, 512, 10, 10, 10])\n",
    "\n",
    "# calculate cummulative runtime for bayes and random search.\n",
    "results = bayesian_optimization(objective_function, lower, upper, num_iterations=50)\n",
    "hyperparameters = results[\"X\"]\n",
    "runtime_bayes = [runtime[hyperparameter] for hyperparameter in hyperparameters]\n",
    "runtime_bayes = np.cumsum(runtime_bayes)\n",
    "\n",
    "runtime_random = [runtime(getRandomHyperparameters()) for _ in range(50)]\n",
    "runtime_random = np.cumsum(runtime_random)\n",
    "\n",
    "\n",
    "# plot cumultative runtime of bayesian optimization and random testing\n",
    "plt.plot(runtime_bayes)\n",
    "plt.plot(runtime_random)\n",
    "plt.savefig(\"runtimes.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "result = np.zeros(50)\n",
    "# get average incumbent development\n",
    "for _ in range(10):\n",
    "    results = bayesian_optimization(objective_function, lower, upper, num_iterations=50)\n",
    "    incumbents = results[\"incumbent_values\"]\n",
    "    result = np.add(result, incumbents)\n",
    "result = np.divide(result, 10)\n",
    "plt.plot(result)\n",
    "plt.savefig(\"incumbentBayes.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
